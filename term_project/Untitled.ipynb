{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8559c-08f7-42f7-86a4-97a0f3a78d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4500f56a-58f4-440a-93a5-cea17be641ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 층을 클래스로 설정\n",
    "class MultiPerceptron:\n",
    "    def __init__(self, last_layer=None, node=0, activation_param=\"relu\", name=None):\n",
    "        \"\"\"_summary_\n",
    "        Args:\n",
    "            last_layer: 이전 층, 이전층의 데이터 값과 가중치를 통해 입력값을 계산하기 위해 가져옴\n",
    "            node: 사용자 설정 값, 원하는 노드 수 설정\n",
    "            activation_param: 활성화 함수 string 변수\n",
    "            name: 각 층의 이름 설정\n",
    "        \"\"\"\n",
    "        self.tolerance = 1e-15    # 허용 오차\n",
    "        \n",
    "        # 각 활성화 함수 string변수와 함수 매핑\n",
    "        self.activate_func = {\n",
    "            \"relu\": self.relu,\n",
    "            \"sigmoid\": self.sigmoid,\n",
    "            \"step\": self.step,\n",
    "            \"tanh\": self.tanh,\n",
    "            \"identity\": self.identity,\n",
    "            \"softmax\": self.softmax\n",
    "        }\n",
    "        \n",
    "        self.last_layer = last_layer # 이전 층\n",
    "        # activation_param을 통해 함수 매핑하여 넣어준다.\n",
    "        self.activate = self.activate_func[activation_param]  \n",
    "        self.hidden_node = node # 은닉층의 노드의 갯수\n",
    "        self.in_data = None     # 이전 층의 데이터와 가중치의 행렬 계산한 값이 들어온다.\n",
    "        self.w = None           # 현재 층의 가중치\n",
    "        self.out_data = None    # 입력으로 들어온 데이터를 활성화 함수를 거치게 한 값 다음 층이나 결과가 된다.\n",
    "        \n",
    "        self.name=name # Debug용, 각 은닉층의 이름 지정\n",
    "    \n",
    "    \n",
    "    def neuron(self):\n",
    "        \"\"\"_summary_\n",
    "            퍼셉트론의 계산을 진행하는 주요 함수\n",
    "            이전층의 출력값과 가중치 값의 행렬 계산 => 입력 => 활성화 함수 => 출력 => (다음 층)\n",
    "        \"\"\"\n",
    "        # 이전 레이어와 가중치의 곱으로 퍼셉트론 계산\n",
    "        tmp = self.layer_calc()\n",
    "        \n",
    "        # 활성화 전 곱으로 들어온 값, 입력 데이터에 저장\n",
    "        self.in_data = tmp\n",
    "        \n",
    "        # 입력 데이터 활성화해서 넘겨줌\n",
    "        tmp = self.activate_loop(tmp)\n",
    "        \n",
    "        # 활성화를 거친 값을 출력 값으로 지정\n",
    "        self.out_data = tmp\n",
    "    \n",
    "    \n",
    "    def layer_calc(self):\n",
    "        \"\"\"_summary_\n",
    "        이전 층의 출력값과 가중치 값의 행렬 계산\n",
    "        Returns: 행렬 계산 값\n",
    "        \"\"\"\n",
    "        # 계산 후\n",
    "        x_b = np.c_[self.last_layer.out_data, np.ones(len(self.last_layer.out_data))]\n",
    "        tmp = x_b.dot(self.last_layer.w)\n",
    "        \n",
    "        return tmp\n",
    "    \n",
    "    def activate_loop(self, tmp):\n",
    "        \"\"\"_summary_\n",
    "        각 데이터 셋에 대해서 적용 시키기위한 함수\n",
    "        Args: tmp: 행렬 계산된 값, \n",
    "        Returns:  활성화 함수를 거친 값\n",
    "        \"\"\"\n",
    "        for i, data in enumerate(tmp):\n",
    "            tmp[i] = self.activate(data)\n",
    "        return tmp\n",
    "                \n",
    "    # 아래는 활성화 함수\n",
    "    # 시그모이드 함수\n",
    "    def sigmoid(self, x): \n",
    "        x = 1 / ( 1 + np.exp(-x))\n",
    "        return x\n",
    "\n",
    "    # 계단 함수\n",
    "    def step(self, x):\n",
    "        return x > 0\n",
    "\n",
    "    # 하이퍼볼릭 탄젠트 함수\n",
    "    def tanh(self, x):\n",
    "        return (np.exp(x) - np.exp(-x))\\\n",
    "                / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "    # 항등 함수\n",
    "    def identity(self, x):\n",
    "        return x\n",
    "    \n",
    "    # Softmax 함수\n",
    "    def softmax(self, x):\n",
    "        e = np.exp(x - np.max(x))\n",
    "        s = np.sum(e)\n",
    "        return e / s\n",
    "    \n",
    "    # ReLU함수\n",
    "    def relu(self, x):\n",
    "        return list(map(lambda d: d if d>0 else 0, x))\n",
    "    \n",
    "# 모델\n",
    "class customModel:\n",
    "    \"\"\"_summary_\n",
    "        모든 퍼셉트론 층을 담아두는 함수\n",
    "    \"\"\"\n",
    "    def __init__(self,x=[], y=[], mean=0, mu=2):\n",
    "        \"\"\"_summary\n",
    "        Args:\n",
    "            x: 입력 데이터, 입력데이터는 항상 numpy array로 준다.\n",
    "            y: 레이블 데이터\n",
    "            mean mu, 랜덤값을 위한 평균과 분산\n",
    "            hidden_layer: 은닉층의 수\n",
    "        \"\"\"\n",
    "        # 모델 전체 layer와 가중치 담아두는 리스트\n",
    "        self.layer= []\n",
    "        self.weight = []\n",
    "        \n",
    "        # 랜덤하게 가중치 생성을 위한 평균과 분산\n",
    "        self.mean = mean\n",
    "        self.mu = mu\n",
    "        \n",
    "        self.label=y        # 라벨 값\n",
    "        self.in_data = x    # 처음 데이터 셋\n",
    "        self.out_data = []  # 출력을 위한 값\n",
    "        self.y_pred = []    # 출력을 통해 예측한 값\n",
    "        \n",
    "        self.input_feature_cnt = 0 # 입력 데이터의 특성 수\n",
    "        self.output_class_cnt = 0  # 출력 결과의 클래스 수\n",
    "        self.hidden_layer_cnt = 0  # 은닉층의 수\n",
    "        \n",
    "        self.check_feature_class_cnt() # 입력 데이터의 특성 수와 출력 결과 클래스 수 파악\n",
    "      \n",
    "    # 퍼셉트론을 통해 도출한 결과 반환하는 함수          \n",
    "    def return_output(self):\n",
    "        return self.out_data\n",
    "    \n",
    "    # softmax함수를 나온 값을 통해 결과 값 도출\n",
    "    def softmax_predict(self):\n",
    "        for d in self.out_data:\n",
    "            # 입력 데이터마다 각각의 최대 값의 인덱스를 통해 결과 값 도출\n",
    "            self.y_pred.append(np.argmax(d)+1)\n",
    "    \n",
    "        return self.y_pred\n",
    "    \n",
    "    # 설계한 은닉층과 출력층을 실질적으로 데이터를 넣어 실행시키는 함수 \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "            입력 데이터 : row, col\n",
    "        \"\"\"\n",
    "        \n",
    "        # 모델로 들어온 데이터 입력 데이터에 넣는다.\n",
    "        # layer0 = 입력층, 입력층은 아무 것도 설정하지 않으므로 입력 데이터 -> 출력 데이터\n",
    "        self.layer[0].in_data = self.in_data\n",
    "        self.layer[0].out_data = self.in_data\n",
    "        \n",
    "        # 설계한 은닉층에서 출력층까지 돌린다.\n",
    "        # MultiPerceptron 클래스에서 내부적으로 이전 layer를 가지고 있으므로 돌려주기만 하면 된다.\n",
    "        for i in range(1,self.hidden_layer_cnt+2):\n",
    "            self.layer[i].neuron()\n",
    "        \n",
    "        # 마지막 출력층의 활성화 함수까지 거친 데이터를 최종 출력 데이터에 넣는다. \n",
    "        self.out_data = self.layer[-1].out_data\n",
    "        \n",
    "    \n",
    "    # 모델 클래스 생성시 입력데이터를 통해 입력 특성 수 지정하고 \n",
    "    # 라벨데이터를 통해 출력 클래스 개수 정하는 함수\n",
    "    def check_feature_class_cnt(self):\n",
    "        # numpy인 경우에만 사용\n",
    "        if type(self.in_data) is np.ndarray:\n",
    "            self.input_feature_cnt = len(self.in_data[0])\n",
    "            \n",
    "        if type(self.label) is np.ndarray:\n",
    "            self.output_class_cnt = len(self.label[0])\n",
    "    \n",
    "    # 가중치 세팅\n",
    "    def set_weight(self, auto=True):\n",
    "        \"\"\"_summary_\n",
    "        Args:\n",
    "            auto: True=자동으로 가중치값을 설정해 준다. False=실습2번\n",
    "        \"\"\"\n",
    "        # 실습 2번을 위한 자동 설정 값\n",
    "        if not auto:\n",
    "            index = 0\n",
    "            # Layer 1\n",
    "            self.weight.append(np.array([\n",
    "                [0.1,0.2,0.3],\n",
    "                [0.1,0.3,0.5],\n",
    "                [0.2,0.4,0.6]\n",
    "            ]))\n",
    "            self.layer[index].w = self.weight[index]\n",
    "\n",
    "            index += 1\n",
    "            # Layer 2\n",
    "            self.weight.append(np.array([\n",
    "                [0.1,0.2],\n",
    "                [0.1,0.4],\n",
    "                [0.2,0.5],\n",
    "                [0.3,0.6]\n",
    "            ]))\n",
    "            self.layer[index].w = self.weight[index]\n",
    "            return\n",
    "\n",
    "        # AUTO\n",
    "        # Input\n",
    "        # 입력층 - 은닉1층 \n",
    "        # matrix = 입력 특성수 x 은닉1층의 노드 수\n",
    "        w =np.random.normal(self.mean,self.mu, size=(self.input_feature_cnt + 1,self.layer[1].hidden_node))\n",
    "        self.weight.append(w) # 설정한 가중치 값 model에 list로 저장\n",
    "        self.layer[0].w = w   # 각 layer(MultiPerceptron 클래스)에 자신의 가중치 저장\n",
    "        \n",
    "        # Hidden - Output\n",
    "        # matrix = 은닉층의 노드 x 출력층 클래스 수\n",
    "        # 은닉층만 적용\n",
    "        for i in range(1, self.hidden_layer_cnt+1):\n",
    "            w =np.random.normal(self.mean,self.mu, size=(self.layer[i].hidden_node+1,self.layer[i+1].hidden_node))\n",
    "            self.layer[i].w = w # 자신의 클래스에 값 저장\n",
    "            self.weight.append(w) # 설정한 가중치 값 model에 list로 저장 \n",
    "        \n",
    "    # 실습#2 Case 1\n",
    "    def set_layer_case1(self):\n",
    "        # input = 이전 레이어\n",
    "        # node = 원하는 입력 층 수\n",
    "        # name = 층의 이름 설정\n",
    "        # activation_param = 활성화 함수, 자신한테 들어온 데이터를 활성화 함수를 통해 비선형적이게 만들어 다음 층으로 넘긴다. \n",
    "        \n",
    "        # 입력 층 설정\n",
    "        # 입력층의 노드 = 입력 데이터의 특성 수\n",
    "        input = MultiPerceptron(node=self.input_feature_cnt, name=\"Input_Layer\")\n",
    "        self.layer.append(input)\n",
    "        \n",
    "        # 은닉층1: {활성화함수:시그모이드, node=3}으로 지정\n",
    "        layer1 = MultiPerceptron(input, node=3, activation_param=\"sigmoid\", name=\"Layer1\")\n",
    "        self.layer.append(layer1)\n",
    "        \n",
    "        # 출력층: {활성화함수:identity(항등), node=출력 클래스 갯수}으로 지정\n",
    "        output = MultiPerceptron(layer1, node=self.output_class_cnt, activation_param=\"identity\", name=\"Output_Layer\")\n",
    "        self.layer.append(output)\n",
    "        \n",
    "        # 모든 레이어 - 입력 - 출력\n",
    "        self.hidden_layer_cnt = len(self.layer) - 2\n",
    "        \n",
    "        # 모델 설계후 각 지정한 노드를 통해 가중치 설정\n",
    "        self.set_weight(auto=False)\n",
    "        \n",
    "     # 실습#2 Case 2\n",
    "    def set_layer_case2(self):\n",
    "         # 입력 층 설정\n",
    "        # 입력층의 노드 = 입력 데이터의 특성 수\n",
    "        input_data = MultiPerceptron(node=self.input_feature_cnt, name=\"Input_Layer\")\n",
    "        self.layer.append(input_data)\n",
    "        \n",
    "        # 은닉층1: {활성화함수:시그모이드, node=3}으로 지정\n",
    "        layer1 = MultiPerceptron(input_data, node=3, activation_param=\"sigmoid\", name=\"Layer1\")\n",
    "        self.layer.append(layer1)\n",
    "        \n",
    "        # 출력층: {활성화함수:softmax, node=출력 클래스 갯수}으로 지정\n",
    "        output = MultiPerceptron(layer1, node=self.output_class_cnt, activation_param=\"softmax\", name=\"Output_Layer\")\n",
    "        self.layer.append(output)\n",
    "        \n",
    "        # 모든 레이어 - 입력 - 출력\n",
    "        self.hidden_layer_cnt = len(self.layer) - 2\n",
    "        \n",
    "        # 모델 설계후 각 지정한 노드를 통해 가중치 설정\n",
    "        self.set_weight(auto=False)\n",
    "        \n",
    "    # 실습#2 Case 3  \n",
    "    def set_layer_case3(self):\n",
    "        # 입력 층 설정\n",
    "        # 입력층의 노드 = 입력 데이터의 특성 수\n",
    "        input_data = MultiPerceptron(node=self.input_feature_cnt, name=\"Input_Layer\")\n",
    "        self.layer.append(input_data)\n",
    "        \n",
    "        # 은닉층1: {활성화함수:relu, node=3}으로 지정\n",
    "        layer1 = MultiPerceptron(input_data, node=3, activation_param=\"relu\", name=\"Layer1\")\n",
    "        self.layer.append(layer1)\n",
    "        \n",
    "        # 출력층: {활성화함수:identity, node=출력 클래스 갯수}으로 지정\n",
    "        output = MultiPerceptron(layer1, node=self.output_class_cnt, activation_param=\"identity\", name=\"Output_Layer\")\n",
    "        self.layer.append(output)\n",
    "        \n",
    "        # 모든 레이어 - 입력 - 출력\n",
    "        self.hidden_layer_cnt = len(self.layer) - 2\n",
    "        # 모델 설계후 각 지정한 노드를 통해 가중치 설정\n",
    "        self.set_weight(auto=False)\n",
    "        \n",
    "    # 실습#2 Case 4\n",
    "    def set_layer_case4(self):\n",
    "        # 입력 층 설정\n",
    "        # 입력층의 노드 = 입력 데이터의 특성 수\n",
    "        input_data = MultiPerceptron(node=self.input_feature_cnt, name=\"Input_Layer\")\n",
    "        self.layer.append(input_data)\n",
    "        \n",
    "        # 은닉층1: {활성화함수:relu, node=3}으로 지정\n",
    "        layer1= MultiPerceptron(input_data, node=3, activation_param=\"relu\", name=\"Layer1\")\n",
    "        self.layer.append(layer1)\n",
    "        \n",
    "        # 출력층: {활성화함수:softmax, node=출력 클래스 갯수}으로 지정\n",
    "        output = MultiPerceptron(layer1, node=self.output_class_cnt, activation_param=\"softmax\", name=\"Output_Layer\")\n",
    "        self.layer.append(output)\n",
    "        \n",
    "        # 모든 레이어 - 입력 - 출력\n",
    "        self.hidden_layer_cnt = len(self.layer) - 2\n",
    "        # 모델 설계후 각 지정한 노드를 통해 가중치 설정\n",
    "        self.set_weight(auto=False)\n",
    "      \n",
    "    # 실습 #3 \n",
    "    def set_layer(self):\n",
    "        # 입력 층 설정\n",
    "        # 입력층의 노드 = 입력 데이터의 특성 수\n",
    "        input_data = MultiPerceptron(node=self.input_feature_cnt, name=\"Input_Layer\")\n",
    "        self.layer.append(input_data)\n",
    "        \n",
    "        # 은닉층1: {활성화함수:tanh, node=7}으로 지정\n",
    "        layer1= MultiPerceptron(input_data, node=10, activation_param=\"tanh\", name=\"Layer1\")\n",
    "        self.layer.append(layer1)\n",
    "        \n",
    "        # 출력층: {활성화함수:softmax, node=출력 클래스 갯수}으로 지정\n",
    "        output = MultiPerceptron(layer1, node=self.output_class_cnt, activation_param=\"softmax\", name=\"Output_Layer\")\n",
    "        self.layer.append(output)\n",
    "        \n",
    "        # 모든 레이어 - 입력 - 출력\n",
    "        self.hidden_layer_cnt = len(self.layer) - 2\n",
    "        \n",
    "        # 모델 설계후 각 지정한 노드를 통해 가중치 설정\n",
    "        self.set_weight()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
